{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbfaeb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBRegressor\n",
    "from datetime import datetime\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e87fb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather('./dataset/cleaned_train.feather')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189b5e2b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(np.exp(train.SalePrice.median()))\n",
    "print(np.exp(train.SalePrice.mean()))\n",
    "print(np.exp(train.SalePrice.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae55cdf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test = pd.read_feather('./dataset/cleaned_test.feather')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e64572",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train[train.isin([np.nan, -np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84949c67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_target = train.pop(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b29dc5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# monitors improvement or deterioration of the models\n",
    "FILE_REG_PATH = \"./regression_models.csv\"\n",
    "\n",
    "df_regression = pd.read_csv(FILE_REG_PATH, sep=\",\", index_col=0)\n",
    "date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81a5c98",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399535d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train,\n",
    "    train_target,\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f03722",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4355fb8d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "def rmse_CV(model, X, y):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring =\"neg_mean_squared_error\", cv=kf))\n",
    "    return np.exp(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dd6191",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Le RMSE permet de calculer la distance moyenne entre la target et la prédiction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9aadd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(model, X, y, test_X, test_y):\n",
    "    m = model.fit(X, y)\n",
    "    pred_train = m.predict(X)\n",
    "    pred_test  = m.predict(test_X)\n",
    "    rmse_train = rmse_CV(m, X, y).mean()\n",
    "    rmse_test = rmse_CV(m, test_X, test_y).mean()\n",
    "    print(\"rmse on train set\", rmse_train)\n",
    "    print(\"rmse on test set\", rmse_test)\n",
    "    \n",
    "    return m, pred_train, pred_test, rmse_train, rmse_test\n",
    "\n",
    "def fill_regression(d_frame, model_name, params, rmse_train, rmse_test, comment):\n",
    "    return d_frame.append({\"date\": date, \"model_name\": model_name, \"params\": params,\n",
    "                                   \"rmse_train\": rmse_train, \"rmse_test\": rmse_test, \"comment\": comment}, \n",
    "                                   ignore_index=True)\n",
    "    \n",
    "\n",
    "def residuals_plot(pred_train, train_y, pred_test, test_y, title):\n",
    "    plt.scatter(pred_train, pred_train - train_y, c=\"blue\",  label=\"Training data\")\n",
    "    plt.scatter(pred_test, pred_test - test_y, c=\"green\",  label=\"Validation data\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.hlines(y=0, xmin=pred_train.min(), xmax=pred_train.max(), color=\"red\")\n",
    "    plt.show()\n",
    "    \n",
    "def linear_plot(pred_train, train_y, pred_test, test_y, title):\n",
    "    plt.scatter(pred_train, train_y, c=\"blue\",  label=\"Training data\")\n",
    "    plt.scatter(pred_test, test_y, c=\"green\",  label=\"Validation data\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Real values\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.plot([pred_train.min(), pred_train.max()], [pred_train.min(), pred_train.max()], c=\"red\")\n",
    "    plt.show()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195134f9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71734b5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "lr, train_lr, test_lr, rmse_train_lr, rmse_test_lr = prediction(LinearRegression(), X_train, y_train, X_test, y_test)\n",
    "residuals_plot(train_lr, y_train, test_lr, y_test, \"Linear regression residuals\")\n",
    "linear_plot(train_lr, y_train, test_lr, y_test, \"Linear regression real values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78256732",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Les points residuelles sont dispersés de manière **random** autour de l'axe horizontal, on peut utiliser un modèle linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1038e48d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d417afe7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression, SelectKBest, f_regression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abc0cd2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997fedd0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)\n",
    "sel.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712b87b8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    len([\n",
    "        x for x in train.columns\n",
    "        if x not in train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "train_sel = [x for x in train.columns if x not in train.columns[sel.get_support()]]\n",
    "print(train_sel[:5])\n",
    "\n",
    "train = train.loc[:, ~train.columns.isin(train_sel)]\n",
    "print(train.shape)\n",
    "test =  test.loc[:, ~test.columns.isin(train_sel)]\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35cc400b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Univariate features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d7e6f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fs = SelectKBest(score_func=f_regression, k=10)\n",
    "# df_fs = fs.fit_transform(df, df_target)\n",
    "# df_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5387fc7c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ecc7fd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2328cdc0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:  # we are interested in absolute coefficient value\n",
    "                col_name = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(col_name)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(train, 0.75)\n",
    "print(corr_features)\n",
    "\n",
    "train = train.loc[:, ~train.columns.isin(corr_features)]\n",
    "test =  test.loc[:, ~test.columns.isin(corr_features)]\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee64368",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# sfs1 = SFS(RandomForestRegressor(), \n",
    "#            k_features=10, \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=2,\n",
    "#            scoring='r2',\n",
    "#            cv=3)\n",
    "\n",
    "# sfs1 = sfs1.fit(np.array(df_corr), df_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e378044",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c36437",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# df.columns[list(sfs1.k_feature_idx_)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bea2e3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Feature Utility Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34ba789",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores    \n",
    "    \n",
    "def drop_uninformative(df, mi_scores):\n",
    "    return df.loc[:, df.columns.isin(mi_scores[mi_scores > 0.0].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd0aebf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(train, train_target)\n",
    "mi_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6b089",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train = drop_uninformative(train, mi_scores)\n",
    "test  = drop_uninformative(test, mi_scores)\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f839a9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605045ea",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "transformer = StandardScaler().fit(train)\n",
    "\n",
    "train_scaled = transformer.transform(train)\n",
    "test_scaled = transformer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce03b27",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_scaled,\n",
    "    train_target,\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3e499b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Regularization is a very useful method to handle collinearity, filter out noise from data, and eventually prevent overfitting.\n",
    "\n",
    "The concept behind regularization is to introduce additional information (bias) to penalize extreme parameter weights.\n",
    "\n",
    "Ridge and Lasso Regression are types of Regularization techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb59b20",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87b709e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# ridge, train_ridge, test_ridge = prediction(\n",
    "#     RidgeCV(alphas=[0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60]), X_train, y_train, X_test, y_test\n",
    "# )\n",
    "\n",
    "# alpha = ridge.alpha_\n",
    "# print('Best alpha', alpha)\n",
    "\n",
    "# ridge, train_ridge, test_ridge = prediction(\n",
    "#     RidgeCV(alphas=[alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "#                           alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "#                           alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], cv=5), \n",
    "#     X_train, y_train, X_test, y_test\n",
    "# )\n",
    "\n",
    "# alpha = ridge.alpha_\n",
    "# print(\"Best alpha :\", alpha)\n",
    "\n",
    "# residuals_plot(train_ridge, y_train, test_ridge, y_test, \"Ridge regression residuals\")\n",
    "# linear_plot(train_ridge, y_train, test_ridge, y_test, \"Ridge regression real values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0803bc22",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### LASSO Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7700ef7e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# lasso, train_lasso, test_lasso = prediction(\n",
    "#     LassoCV(alphas = [1, 0.1, 0.001, 0.0005]), X_train, y_train, X_test, y_test\n",
    "# )\n",
    "\n",
    "# residuals_plot(train_lasso, y_train, test_lasso, y_test, \"Lasso regression residuals\")\n",
    "# linear_plot(train_lasso, y_train, test_lasso, y_test, \"Lasso regression real values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2099677",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# coef_lasso = pd.Series(lasso.coef_, index=train.columns)\n",
    "\n",
    "# print(\"Lasso picked \" + str(sum(coef_lasso != 0)) + \" variables and eliminated the other \" +  str(sum(coef_lasso == 0)) + \" variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2403bb8e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# imp_coef = pd.concat([coef_lasso.sort_values().head(10),\n",
    "#                      coef_lasso.sort_values().tail(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f464c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# imp_coef.plot(kind = \"barh\")\n",
    "# plt.title(\"Coefficients in the Lasso Model\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6cac19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pour les coeffs négatifs, voir unbalanced categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c089d9ad",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ef84fd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]\n",
    "l1ratio = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b160ddba",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "elasticnet, train_elasticnet, test_elasticnet, rmse_train_elasticnet, rmse_test_elasticnet = prediction(\n",
    "    ElasticNetCV(max_iter=1e7, alphas=alphas, l1_ratio=l1ratio), X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "print(\"best alpha\", elasticnet.alpha_)\n",
    "print(\"best intercept\", elasticnet.intercept_)\n",
    "\n",
    "residuals_plot(train_elasticnet, y_train, test_elasticnet, y_test, \"ElasticNet regression residuals\")\n",
    "linear_plot(train_elasticnet, y_train, test_elasticnet, y_test, \"ElasticNet regression real values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a01a92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_regression = fill_regression(\n",
    "    df_regression, \"ElasticNetCV()\", {\"alpha\":elasticnet.alpha_, \"l1ratio\":  elasticnet.l1_ratio_}, \n",
    "    rmse_train_elasticnet, rmse_test_elasticnet, \"After features selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c39df3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875f70c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train,\n",
    "    train_target,\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093abd40",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    xgb_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-0, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 6000),\n",
    "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    return rmse_CV(xgb, X_train, y_train).mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "xgb_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b672119",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(**xgb_params)\n",
    "\n",
    "xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "pred_xgb = xgb.predict(X_train)\n",
    "pred_test_xgb = xgb.predict(X_test)\n",
    "\n",
    "rmse_train_xgb = rmse_CV(xgb, X_train, y_train).mean()\n",
    "rmse_test_xgb = rmse_CV(xgb, X_test, y_test).mean()\n",
    "\n",
    "print('rmse on train set', rmse_train_xgb)\n",
    "print('rmse on test set', rmse_test_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7f37a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "residuals_plot(pred_xgb, y_train, pred_test_xgb, y_test, \"XGBoost residuals\")\n",
    "linear_plot(pred_xgb, y_train, pred_test_xgb, y_test, \"XGBoost real values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fdf915a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_regression = fill_regression(\n",
    "    df_regression, \"XGBRegressor()\", xgb_params, \n",
    "    rmse_train_xgb, rmse_test_xgb, \"After features selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91440ff",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42539f4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pour chaque modèle, nous avons ajouté à notre dataframe `df_regression` les valeurs RMSE.      \n",
    "Cela doit nous permettre de surveiller si nos algorithmes ce sont dégradés par rapport au passé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e13090",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_regression[\"diff_train\"] = df_regression[df_regression.date == date].rmse_train - df_regression[\n",
    "    df_regression.date != date].rmse_train.min()\n",
    "\n",
    "worst_reg = df_regression[df_regression.diff_train > 0]\n",
    "\n",
    "assert len(worst_reg) == 0, f\"La performance de {', '.join(worst_reg.model_name.values)} sur le train set \\ \n",
    "ce sont dégradés de {worst_reg.diff_train.values}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e94b1",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_regression[\"diff_test\"] = df_regression[df_regression.date == date].rmse_test - df_regression[\n",
    "    df_regression.date != date].rmse_test.min()\n",
    "\n",
    "worst_reg = df_regression[df_regression.diff_test > 0]\n",
    "\n",
    "assert len(worst_reg) == 0, f\"La performance de {', '.join(worst_reg.model_name.values)} sur le test_set ce sont dégradés \\\n",
    "de {worst_reg.diff_test.values}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3a2612",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "On compare, les indicateurs de performance du train et test sets, par rapport aux meilleurs performances passées.     \n",
    "En utilisant un assert, le notebook sera interrompu si une exception est relevée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4320bb34",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20250ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pred = np.exp(xgb.predict(test))\n",
    "\n",
    "results = pd.concat([test, pd.DataFrame({\"SalePrice\": pred})], axis=1)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120cadf0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# q1 = results['SalePrice'].quantile(0.005)\n",
    "# q2 = results['SalePrice'].quantile(0.995)\n",
    "\n",
    "# results['SalePrice'] = results['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "# results['SalePrice'] = results['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7972192e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(results['SalePrice'].median())\n",
    "print(results['SalePrice'].mean())\n",
    "print(results['SalePrice'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b1533b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_regression.iloc[:, :-2].to_csv(FILE_REG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b68d07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
