{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bbfaeb",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set Matplotlib defaults\n",
    "plt.style.use(\"seaborn-whitegrid\")\n",
    "plt.rc(\"figure\", autolayout=True)\n",
    "plt.rc(\n",
    "    \"axes\",\n",
    "    labelweight=\"bold\",\n",
    "    labelsize=\"large\",\n",
    "    titleweight=\"bold\",\n",
    "    titlesize=14,\n",
    "    titlepad=10,\n",
    ")\n",
    "\n",
    "# Mute warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e87fb0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather('./dataset/cleaned_train.feather')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05d1886",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.exp(train.SalePrice.median()))\n",
    "print(np.exp(train.SalePrice.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159da7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_feather('./dataset/cleaned_test.feather')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c80ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train[train.isin([np.nan, -np.nan, np.inf, -np.inf]).any(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196940e3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_target = train.pop(\"SalePrice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a020724",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.exp(train_target.median()))\n",
    "print(np.exp(train_target.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff4ba30",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd7a42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_regression, SelectKBest, f_regression\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda55534",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Constant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb21df5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sel = VarianceThreshold(threshold=0.01)\n",
    "sel.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bef8f0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    len([\n",
    "        x for x in train.columns\n",
    "        if x not in train.columns[sel.get_support()]\n",
    "    ]))\n",
    "\n",
    "train_sel = [x for x in train.columns if x not in train.columns[sel.get_support()]]\n",
    "\n",
    "train = train.loc[:, ~train.columns.isin(train_sel)]\n",
    "test =  test.loc[:, ~test.columns.isin(train_sel)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd541b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Univariate features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f18e3c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fs = SelectKBest(score_func=f_regression, k=10)\n",
    "# df_fs = fs.fit_transform(df, df_target)\n",
    "# df_fs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d30373",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fs.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e29356",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Redundant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def correlation(dataset, threshold):\n",
    "    col_corr = set()  # Set of all the names of correlated columns\n",
    "    corr_matrix = dataset.corr()\n",
    "    for i in range(len(corr_matrix.columns)):\n",
    "        for j in range(i):\n",
    "            if abs(corr_matrix.iloc[i, j]) > threshold:  # we are interested in absolute coefficient value\n",
    "                col_name = corr_matrix.columns[i]  # getting the name of column\n",
    "                col_corr.add(col_name)\n",
    "    return col_corr\n",
    "\n",
    "corr_features = correlation(train, 0.75)  # 0.5\n",
    "\n",
    "train = train.loc[:, ~train.columns.isin(corr_features)]\n",
    "test =  test.loc[:, ~test.columns.isin(corr_features)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "\n",
    "# sfs1 = SFS(RandomForestRegressor(), \n",
    "#            k_features=10, \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=2,\n",
    "#            scoring='r2',\n",
    "#            cv=3)\n",
    "\n",
    "# sfs1 = sfs1.fit(np.array(df_corr), df_target)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# sfs1.k_feature_idx_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# df.columns[list(sfs1.k_feature_idx_)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Feature Utility Scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def make_mi_scores(X, y):\n",
    "    mi_scores = mutual_info_regression(X, y, random_state=0)\n",
    "    mi_scores = pd.Series(mi_scores, name=\"MI Scores\", index=X.columns)\n",
    "    mi_scores = mi_scores.sort_values(ascending=False)\n",
    "    return mi_scores\n",
    "\n",
    "\n",
    "def plot_mi_scores(scores):\n",
    "    scores = scores.sort_values(ascending=True)\n",
    "    width = np.arange(len(scores))\n",
    "    ticks = list(scores.index)\n",
    "    plt.barh(width, scores)\n",
    "    plt.yticks(width, ticks)\n",
    "    plt.title(\"Mutual Information Scores\")\n",
    "    \n",
    "    \n",
    "def drop_uninformative(df, mi_scores):\n",
    "    return df.loc[:, df.columns.isin(mi_scores[mi_scores > 0.0].index)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "mi_scores = make_mi_scores(train, train_target)\n",
    "mi_scores"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train = drop_uninformative(train, mi_scores)\n",
    "test  = drop_uninformative(test, mi_scores)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from xgboost import XGBRegressor"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "transformer = RobustScaler().fit(train)\n",
    "\n",
    "train_scaled = transformer.transform(train)\n",
    "test_scaled = transformer.transform(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    train_scaled,\n",
    "    train_target,\n",
    "    test_size=0.3,\n",
    "    random_state=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross-Validation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_folds = 5\n",
    "\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "def rmse_CV(model, X, y):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(train.values)\n",
    "    rmse = np.sqrt(-cross_val_score(model, X, y, scoring =\"neg_mean_squared_error\", cv=kf))\n",
    "    return (rmse)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We are checking how model is performing on our own data\n",
    "\n",
    "What is the difference between test data and validation data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def prediction(model, X, y, test_X, test_y):\n",
    "    m = model.fit(X, y)\n",
    "    pred_train = m.predict(X)\n",
    "    pred_test  = m.predict(test_X)\n",
    "    print('rmse on train set', rmse_CV(m, X, y).mean())\n",
    "    print('rmse on test set', rmse_CV(m, test_X, test_y).mean())\n",
    "    \n",
    "    return m, pred_train, pred_test\n",
    "\n",
    "def residuals_plot(pred_train, train_y, pred_test, test_y, title):\n",
    "    plt.scatter(pred_train, pred_train - train_y, c=\"blue\",  label=\"Training data\")\n",
    "    plt.scatter(pred_test, pred_test - test_y, c=\"green\",  label=\"Validation data\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Residuals\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.hlines(y=0, xmin=pred_train.min(), xmax=pred_train.max(), color=\"red\")\n",
    "    plt.show()\n",
    "    \n",
    "def linear_plot(pred_train, train_y, pred_test, test_y, title):\n",
    "    plt.scatter(pred_train, train_y, c=\"blue\",  label=\"Training data\")\n",
    "    plt.scatter(pred_test, test_y, c=\"green\",  label=\"Validation data\")\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted values\")\n",
    "    plt.ylabel(\"Real values\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.plot([pred_train.min(), pred_train.max()], [pred_train.min(), pred_train.max()], c=\"red\")\n",
    "    plt.show()   "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Linear Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lr, train_lr, test_lr = prediction(LinearRegression(), X_train, y_train, X_test, y_test)\n",
    "# residuals_plot(train_lr, y_train, test_lr, y_test, \"Linear regression residuals\")\n",
    "# linear_plot(train_lr, y_train, test_lr, y_test, \"Linear regression real values\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Les points residuelles sont dispersés de manière **random** autour de l'axe horizontal, on peut utiliser un modèle linéaire."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Regularization is a very useful method to handle collinearity, filter out noise from data, and eventually prevent overfitting.\n",
    "\n",
    "The concept behind regularization is to introduce additional information (bias) to penalize extreme parameter weights.\n",
    "\n",
    "Ridge and Lasso Regression are types of Regularization techniques"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ridge Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ridge, train_ridge, test_ridge = prediction(\n",
    "#     RidgeCV(alphas=[0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60]), X_train, y_train, X_test, y_test\n",
    "# )\n",
    "\n",
    "# alpha = ridge.alpha_\n",
    "# print('Best alpha', alpha)\n",
    "\n",
    "# ridge, train_ridge, test_ridge = prediction(\n",
    "#     RidgeCV(alphas=[alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "#                           alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "#                           alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], cv=5), \n",
    "#     X_train, y_train, X_test, y_test\n",
    "# )\n",
    "\n",
    "# alpha = ridge.alpha_\n",
    "# print(\"Best alpha :\", alpha)\n",
    "\n",
    "# residuals_plot(train_ridge, y_train, test_ridge, y_test, \"Ridge regression residuals\")\n",
    "# linear_plot(train_ridge, y_train, test_ridge, y_test, \"Ridge regression real values\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LASSO Regression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lasso, train_lasso, test_lasso = prediction(\n",
    "#     LassoCV(alphas = [1, 0.1, 0.001, 0.0005]), X_train, y_train, X_test, y_test\n",
    "# )\n",
    "\n",
    "# residuals_plot(train_lasso, y_train, test_lasso, y_test, \"Lasso regression residuals\")\n",
    "# linear_plot(train_lasso, y_train, test_lasso, y_test, \"Lasso regression real values\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# coef_lasso = pd.Series(lasso.coef_, index=train.columns)\n",
    "\n",
    "# print(\"Lasso picked \" + str(sum(coef_lasso != 0)) + \" variables and eliminated the other \" +  str(sum(coef_lasso == 0)) + \" variables\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# imp_coef = pd.concat([coef_lasso.sort_values().head(10),\n",
    "#                      coef_lasso.sort_values().tail(10)])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# imp_coef.plot(kind = \"barh\")\n",
    "# plt.title(\"Coefficients in the Lasso Model\");"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Pour les coeffs négatifs, voir unbalanced categorical variables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### ElasticNet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kfolds = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008, 0.0009]\n",
    "l1ratio = [0.7, 0.75, 0.8, 0.85, 0.9, 0.95, 0.99, 1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "elasticnet, train_elasticnet, test_elasticnet = prediction(\n",
    "    ElasticNetCV(max_iter=1e7, alphas=alphas, l1_ratio=l1ratio), X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "residuals_plot(train_elasticnet, y_train, test_elasticnet, y_test, \"ElasticNet regression residuals\")\n",
    "linear_plot(train_elasticnet, y_train, test_elasticnet, y_test, \"ElasticNet regression real values\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### XGBoost"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    xgb_params = dict(\n",
    "        max_depth=trial.suggest_int(\"max_depth\", 2, 10),\n",
    "        learning_rate=trial.suggest_float(\"learning_rate\", 1e-4, 1e-0, log=True),\n",
    "        n_estimators=trial.suggest_int(\"n_estimators\", 100, 6000),\n",
    "        min_child_weight=trial.suggest_int(\"min_child_weight\", 1, 10),\n",
    "        colsample_bytree=trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
    "        subsample=trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
    "        reg_alpha=trial.suggest_float(\"reg_alpha\", 1e-4, 1e2, log=True),\n",
    "        reg_lambda=trial.suggest_float(\"reg_lambda\", 1e-4, 1e2, log=True),\n",
    "    )\n",
    "    xgb = XGBRegressor(**xgb_params)\n",
    "    return rmse_CV(xgb, X_train, y_train).mean()\n",
    "\n",
    "study = optuna.create_study(direction=\"minimize\")\n",
    "study.optimize(objective, n_trials=20)\n",
    "xgb_params = study.best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb = XGBRegressor(**xgb_params)\n",
    "\n",
    "xgb.fit(X_train, y_train, early_stopping_rounds=5, eval_set=[(X_test, y_test)], verbose=False)\n",
    "\n",
    "pred_test_xgb = np.exp(xgb.predict(X_test))\n",
    "pred_xgb = np.exp(xgb.predict(test_scaled))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot residuals\n",
    "plt.scatter(pred_test_xgb, pred_test_xgb - np.exp(y_test), c=\"blue\",  label=\"Validation data\")\n",
    "\n",
    "plt.title(\"XGBoost regression\")\n",
    "plt.xlabel(\"Predicted values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=pred_test_xgb.min(), xmax=pred_test_xgb.max(), color=\"red\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results = pd.concat([test, pd.DataFrame({\"SalePrice\": pred_xgb})], axis=1)\n",
    "results.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "q1 = results['SalePrice'].quantile(0.005)\n",
    "q2 = results['SalePrice'].quantile(0.995)\n",
    "\n",
    "results['SalePrice'] = results['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "results['SalePrice'] = results['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(results['SalePrice'].median())\n",
    "print(results['SalePrice'].max())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8496b2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = results['SalePrice'].quantile(0.005)\n",
    "q2 = results['SalePrice'].quantile(0.995)\n",
    "\n",
    "results['SalePrice'] = results['SalePrice'].apply(lambda x: x if x > q1 else x*0.77)\n",
    "results['SalePrice'] = results['SalePrice'].apply(lambda x: x if x < q2 else x*1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea893f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results['SalePrice'].median())\n",
    "print(results['SalePrice'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b68d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}